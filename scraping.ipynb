{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jdatetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,json,jdatetime,datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "service=day=month=year=0\n",
    "url = f'https://www.mehrnews.com/archive?pi=1&tp={service}&pl=9&ms=0&dy={day}&mn={month}&yr={year}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we have 3 category   \n",
    "each day have almost 30 rows so each month have 900 rows    \n",
    "so  \n",
    "each month have 900 * 3 = 2700  \n",
    "and each year have = 32400  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now = jdatetime.date.fromgregorian(day=now.day,month=now.month,year=now.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = {'Economy':25,\n",
    "'Sport':9,\n",
    "'Politics' :7,\n",
    "'Health':550}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one years is eaqual 365 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in services.items():\n",
    "    print(key)\n",
    "    filename = str(key) + '.json'\n",
    "    dataset = []\n",
    "    for i in range(365):\n",
    "        temp = now - timedelta(days=i)\n",
    "        url = f'https://www.mehrnews.com/archive?pi=1&tp={value}&pl=9&ms=0&dy={temp.day}&mn={temp.month}&yr={temp.year}'\n",
    "        req = requests.get(url)\n",
    "        soup = BeautifulSoup(req.content,'html.parser')\n",
    "        rows = soup.find_all('li',attrs={'class':'news'})\n",
    "        for row in rows:\n",
    "            d = dict()\n",
    "            d['title'] = row.select_one('h3 a').text.strip()\n",
    "            d['des'] = row.select_one('p').text.strip()\n",
    "            d['time'] = str(temp)\n",
    "            dataset.append(d)\n",
    "    with open(filename,'w') as f:\n",
    "        json.dump(dataset,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'Health.json'\n",
    "dataset = []\n",
    "for i in range(365):\n",
    "    temp = now - timedelta(days=i)\n",
    "    url = f'https://www.mehrnews.com/archive?pi=1&tp=550&pl=9&ms=0&dy={temp.day}&mn={temp.month}&yr={temp.year}'\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.content,'html.parser')\n",
    "    rows = soup.find_all('li',attrs={'class':'news'})\n",
    "    for row in rows:\n",
    "        d = dict()\n",
    "        d['title'] = row.select_one('h3 a').text.strip()\n",
    "        d['des'] = row.select_one('p').text.strip()\n",
    "        d['time'] = str(temp)\n",
    "        dataset.append(d)\n",
    "with open(filename,'w') as f:\n",
    "    json.dump(dataset,f)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c900f103a300001e767ada55af3ac9d455f057f30f8b06dca7de25fa89a2bebe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
